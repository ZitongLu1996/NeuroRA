{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Demo 3: a demo for comparing classification-based decoding and RSA\n",
    "Here is a demo based on the data of Bae&Luck's work in 2018. All demo data are based on their Experiment 2's data. You can find more details about the experiment and data information in their paper: Bae, G.Y., Luck, S.J. (2018). Dissociable decoding of spatial attention and working memory from eeg oscillations and sustained potentials. The Journal of Neuroscience, 38(2), 409-422."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import zipfile\n",
    "import numpy as np\n",
    "import scipy.io as sio\n",
    "import h5py\n",
    "from sklearn.svm import SVC\n",
    "from neurora.stuff import permutation_test\n",
    "from sklearn.metrics import accuracy_score\n",
    "from six.moves import urllib\n",
    "import matplotlib.pyplot as plt\n",
    "from neurora.rdm_cal import eegRDM\n",
    "from neurora.rsa_plot import plot_rdm, plot_tbytsim_withstats\n",
    "from neurora.corr_cal_by_rdm import rdms_corr\n",
    "\n",
    "url = 'https://attachment.zhaokuangshi.cn/BaeLuck_2018jn_data_ERP_5subs.zip'\n",
    "filename = 'BaeLuck_2018jn_data_ERP_5subs.zip'\n",
    "data_dir = 'data/'\n",
    "classification_results_dir = 'classification_results/'\n",
    "ctrsa_results_dir = 'rsa_results/'\n",
    "filepath = data_dir + filename"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 1: Download the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download the data\n",
    "\n",
    "def show_progressbar(str, cur, total=100):\n",
    "\n",
    "    percent = '{:.2%}'.format(cur / total)\n",
    "    sys.stdout.write('\\r')\n",
    "    sys.stdout.write(str + \": [%-100s] %s\" % ('=' * int(cur), percent))\n",
    "    sys.stdout.flush()\n",
    "\n",
    "def schedule(blocknum,blocksize,totalsize):\n",
    "\n",
    "    if totalsize == 0:\n",
    "        percent = 0\n",
    "    else:\n",
    "        percent = blocknum * blocksize / totalsize\n",
    "    if percent > 1.0:\n",
    "        percent = 1.0\n",
    "    percent = percent * 100\n",
    "    show_progressbar(\"Downloading\", percent)\n",
    "\n",
    "exist = os.path.exists(filepath)\n",
    "if exist == False:\n",
    "    os.makedirs(data_dir)\n",
    "    urllib.request.urlretrieve(url, filepath, schedule)\n",
    "    print('Download completes!')\n",
    "elif exist == True:\n",
    "    print('Data already exists!')\n",
    "\n",
    "# unzip the data\n",
    "\n",
    "def unzipfile(filepath, data_dir):\n",
    "\n",
    "    with zipfile.ZipFile(filepath, 'r') as zip:\n",
    "        zip.extractall(data_dir)\n",
    "    print(\"Unzip completes!\")\n",
    "\n",
    "unzipfile(filepath, data_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 2: Classification-based Decoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data preprocessing for classification-based decoding\n",
    "\n",
    "# sub_ids\n",
    "subs = [\"201\", \"202\", \"203\", \"204\", \"205\"]\n",
    "\n",
    "exist = os.path.exists(data_dir + 'data_for_classification/ERP/')\n",
    "if exist == False:\n",
    "    os.makedirs(data_dir + 'data_for_classification/ERP/')\n",
    "\n",
    "for sub in subs:\n",
    "    data = sio.loadmat(data_dir + \"data/ERP\" + sub + \".mat\")[\"filtData\"][:, :, 250:]\n",
    "    print(data.shape)\n",
    "    # data.shape: n_trials, n_channels, n_times\n",
    "\n",
    "    ori_label = np.loadtxt(data_dir + \"labels/ori_\" + sub + \".txt\")[:, 1]\n",
    "    pos_label = np.loadtxt(data_dir + \"labels/pos_\" + sub + \".txt\")[:, 1]\n",
    "\n",
    "    ori_subdata500 = np.zeros([16, 40, 27, 500], dtype=np.float)\n",
    "    pos_subdata500 = np.zeros([16, 40, 27, 500], dtype=np.float)\n",
    "\n",
    "    ori_labelindex = np.zeros([16], dtype=np.int)\n",
    "    pos_labelindex = np.zeros([16], dtype=np.int)\n",
    "\n",
    "    for i in range(640):\n",
    "        label = int(ori_label[i])\n",
    "        ori_subdata500[label, ori_labelindex[label]] = data[i]\n",
    "        ori_labelindex[label] = ori_labelindex[label] + 1\n",
    "        label = int(pos_label[i])\n",
    "        pos_subdata500[label, pos_labelindex[label]] = data[i]\n",
    "        pos_labelindex[label] = pos_labelindex[label] + 1\n",
    "\n",
    "    ori_subdata = np.zeros([16, 40, 27, 100], dtype=np.float)\n",
    "    pos_subdata = np.zeros([16, 40, 27, 100], dtype=np.float)\n",
    "\n",
    "    for t in range(100):\n",
    "        ori_subdata[:, :, :, t] = np.average(ori_subdata500[:, :, :, t * 5:t * 5 + 5], axis=3)\n",
    "        pos_subdata[:, :, :, t] = np.average(pos_subdata500[:, :, :, t * 5:t * 5 + 5], axis=3)\n",
    "\n",
    "    f = h5py.File(data_dir + \"data_for_classification/ERP/\" + sub + \".h5\", \"w\")\n",
    "    f.create_dataset(\"ori\", data=ori_subdata)\n",
    "    f.create_dataset(\"pos\", data=pos_subdata)\n",
    "    f.close()\n",
    "\n",
    "# aftering the preprocessing above,\n",
    "# we can obtain ERP data of orientation and position for each subject\n",
    "# each subject's orientation ERP data's shape is [16, 40, 27, 100]\n",
    "# 16: the number of conditions (here means 16 different orientation degrees)\n",
    "# 40: the number of trials\n",
    "# 27: the number of channels\n",
    "# 100: the number of time-points (from -500 ms to 1500 ms, sample rate: 50 Hz)\n",
    "\n",
    "# Linear-SVM decoding\n",
    "\n",
    "exist = os.path.exists(classification_results_dir)\n",
    "if exist == False:\n",
    "    os.makedirs(classification_results_dir)\n",
    "\n",
    "# orientation decoding\n",
    "print(\"\\nOrientation Decoding!\")\n",
    "subindex = 0\n",
    "if os.path.exists(classification_results_dir + \"ERP_ori.h5\"):\n",
    "    os.remove(classification_results_dir + \"ERP_ori.h5\")\n",
    "f = h5py.File(classification_results_dir + \"ERP_ori.h5\", \"w\")\n",
    "total = len(subs) * 10 * 3 * 100\n",
    "for sub in subs:\n",
    "    fdata = h5py.File(data_dir + \"data_for_classification/ERP/\" + sub + \".h5\", \"r\")\n",
    "    data = np.array(fdata[\"ori\"])\n",
    "    fdata.close()\n",
    "    acc = np.zeros([10, 100, 3], dtype=np.float)\n",
    "    for k in range(10):\n",
    "        index_trials = np.array(range(40))\n",
    "        shuffle = np.random.permutation(index_trials)\n",
    "        newdata = data[:, shuffle[:39]]\n",
    "        block_data = np.zeros([3, 16, 27, 100], dtype=np.float)\n",
    "        for i in range(3):\n",
    "            block_data[i] = np.average(newdata[:, i * 13:i * 13 + 13], axis=1)\n",
    "        y_train = np.zeros([2 * 16], dtype=np.int)\n",
    "        for i in range(2):\n",
    "            for j in range(16):\n",
    "                y_train[i * 16 + j] = j\n",
    "        y_test = np.zeros([16], dtype=np.int)\n",
    "        for i in range(16):\n",
    "            y_test[i] = i\n",
    "        for i in range(3):\n",
    "            x_test = block_data[i]\n",
    "            x_train = np.zeros([2, 16, 27, 100], dtype=np.float)\n",
    "            index = 0\n",
    "            for j in range(3):\n",
    "                if j != i:\n",
    "                    x_train[index] = block_data[j]\n",
    "                    index = index + 1\n",
    "            x_train = np.reshape(x_train, [2 * 16, 27, 100])\n",
    "            for t in range(100):\n",
    "                x_train_t = x_train[:, :, t]\n",
    "                x_test_t = x_test[:, :, t]\n",
    "                svm = SVC(kernel='linear', decision_function_shape='ovr')\n",
    "                svm.fit(x_train_t, y_train)\n",
    "                y_pred = svm.predict(x_test_t)\n",
    "                acc[k, t, i] = accuracy_score(y_test, y_pred)\n",
    "    subindex = subindex + 1\n",
    "    f.create_dataset(sub, data=np.average(acc, axis=(0, 2)))\n",
    "f.close()\n",
    "\n",
    "# orientation decoding\n",
    "print(\"\\nPosition Decoding!\")\n",
    "subindex = 0\n",
    "f = h5py.File(classification_results_dir + \"ERP_pos.h5\", \"w\")\n",
    "total = len(subs) * 10 * 3 * 100\n",
    "for sub in subs:\n",
    "    fdata = h5py.File(data_dir + \"data_for_classification/ERP/\" + sub + \".h5\", \"r\")\n",
    "    data = np.array(fdata[\"pos\"])\n",
    "    fdata.close()\n",
    "    acc = np.zeros([10, 100, 3], dtype=np.float)\n",
    "    for k in range(10):\n",
    "        index_trials = np.array(range(40))\n",
    "        shuffle = np.random.permutation(index_trials)\n",
    "        newdata = data[:, shuffle[:39]]\n",
    "        block_data = np.zeros([3, 16, 27, 100], dtype=np.float)\n",
    "        for i in range(3):\n",
    "            block_data[i] = np.average(newdata[:, i * 13:i * 13 + 13], axis=1)\n",
    "        y_train = np.zeros([2 * 16], dtype=np.int)\n",
    "        for i in range(2):\n",
    "            for j in range(16):\n",
    "                y_train[i * 16 + j] = j\n",
    "        y_test = np.zeros([16], dtype=np.int)\n",
    "        for i in range(16):\n",
    "            y_test[i] = i\n",
    "        for i in range(3):\n",
    "            x_test = block_data[i]\n",
    "            x_train = np.zeros([2, 16, 27, 100], dtype=np.float)\n",
    "            index = 0\n",
    "            for j in range(3):\n",
    "                if j != i:\n",
    "                    x_train[index] = block_data[j]\n",
    "                    index = index + 1\n",
    "            x_train = np.reshape(x_train, [2 * 16, 27, 100])\n",
    "            for t in range(100):\n",
    "                x_train_t = x_train[:, :, t]\n",
    "                x_test_t = x_test[:, :, t]\n",
    "                svm = SVC(kernel='linear', decision_function_shape='ovr')\n",
    "                svm.fit(x_train_t, y_train)\n",
    "                y_pred = svm.predict(x_test_t)\n",
    "                acc[k, t, i] = accuracy_score(y_test, y_pred)\n",
    "    subindex = subindex + 1\n",
    "    f.create_dataset(sub, data=np.average(acc, axis=(0, 2)))\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 3: Plot the classification-based decoding results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the classification-based decoding results\n",
    "\n",
    "# a function for plotting the time-by-time decoding results\n",
    "def plot_tbytresults(decoding_results_dir, subs):\n",
    "    f = h5py.File(decoding_results_dir, \"r\")\n",
    "    nsubs = len(subs)\n",
    "    rlts = np.zeros([nsubs, 100], dtype=np.float)\n",
    "    subindex = 0\n",
    "    for sub in subs:\n",
    "        rlts[subindex] = np.array(f[sub])\n",
    "        for t in range(100):\n",
    "            if t <= 1:\n",
    "                rlts[subindex, t] = np.average(rlts[subindex, :t + 3])\n",
    "            if t > 1 and t < 98:\n",
    "                rlts[subindex, t] = np.average(rlts[subindex, t - 2:t + 3])\n",
    "            if t >= 98:\n",
    "                rlts[subindex, t] = np.average(rlts[subindex, t - 2:])\n",
    "        subindex = subindex + 1\n",
    "    f.close()\n",
    "\n",
    "    avg = np.average(rlts, axis=0)\n",
    "    err = np.zeros([100], dtype=np.float)\n",
    "    for t in range(100):\n",
    "        err[t] = np.std(rlts[:, t], ddof=1) / np.sqrt(nsubs)\n",
    "\n",
    "    ps = np.zeros([100], dtype=np.float)\n",
    "    chance = np.full([16], 0.0625)\n",
    "    for t in range(100):\n",
    "        ps[t] = permutation_test(rlts[:, t], chance)\n",
    "        if ps[t] < 0.05 and avg[t] > 0.0625:\n",
    "            plt.plot(t * 0.02 - 0.5, 0.148, \"s\", color=\"orangered\", alpha=0.8)\n",
    "            xi = [t * 0.02 - 0.5, t * 0.02 + 0.02 - 0.5]\n",
    "            ymin = [0.0625]\n",
    "            ymax = [avg[t] - err[t]]\n",
    "            plt.fill_between(xi, ymax, ymin, facecolor=\"orangered\", alpha=0.15)\n",
    "\n",
    "    ax = plt.gca()\n",
    "    ax.spines[\"top\"].set_visible(False)\n",
    "    ax.spines[\"right\"].set_visible(False)\n",
    "    ax.spines[\"left\"].set_linewidth(3)\n",
    "    ax.spines[\"bottom\"].set_linewidth(3)\n",
    "    ax.spines['bottom'].set_position(('data', 0.0625))\n",
    "    x = np.arange(-0.5 + 0.008, 1.5 + 0.008, 0.02)\n",
    "    plt.fill_between(x, avg + err, avg - err, facecolor=\"orangered\", alpha=0.8)\n",
    "    plt.ylim(0.05, 0.15)\n",
    "    plt.xlim(-0.5, 1.5)\n",
    "    plt.xticks([-0.25, 0, 0.25, 0.5, 0.75, 1, 1.25, 1.5])\n",
    "    plt.tick_params(labelsize=12)\n",
    "    plt.xlabel(\"Time (s)\", fontsize=16)\n",
    "    plt.ylabel(\"Classification Accuracy\", fontsize=16)\n",
    "    plt.show()\n",
    "\n",
    "# plot orientation decoding results\n",
    "print(\"Orientation Classification-based Decoding Results!\")\n",
    "plot_tbytresults(classification_results_dir + \"ERP_ori.h5\", subs)\n",
    "\n",
    "# plot position decoding results\n",
    "print(\"Position Classification-based Decoding Results!\")\n",
    "plot_tbytresults(classification_results_dir + \"ERP_pos.h5\", subs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 4: RSA-based Decoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data preprocessing for classification-based decoding\n",
    "\n",
    "if os.path.exists(data_dir + 'data_for_RSA/ERP/') == False:\n",
    "    os.makedirs(data_dir + 'data_for_RSA/ERP/')\n",
    "\n",
    "n = len(subs)\n",
    "subindex = 0\n",
    "for sub in subs:\n",
    "    data = sio.loadmat(data_dir + \"data/ERP\" + sub + \".mat\")[\"filtData\"][:, :, 250:]\n",
    "    # data.shape: n_trials, n_channels, n_times\n",
    "\n",
    "    ori_label = np.loadtxt(data_dir + \"labels/ori_\" + sub + \".txt\")[:, 1]\n",
    "    pos_label = np.loadtxt(data_dir + \"labels/pos_\" + sub + \".txt\")[:, 1]\n",
    "\n",
    "    ori_subdata = np.zeros([16, 40, 27, 500], dtype=np.float)\n",
    "    pos_subdata = np.zeros([16, 40, 27, 500], dtype=np.float)\n",
    "\n",
    "    ori_labelindex = np.zeros([16], dtype=np.int)\n",
    "    pos_labelindex = np.zeros([16], dtype=np.int)\n",
    "\n",
    "    for i in range(640):\n",
    "        label = int(ori_label[i])\n",
    "        ori_subdata[label, ori_labelindex[label]] = data[i]\n",
    "        ori_labelindex[label] = ori_labelindex[label] + 1\n",
    "        label = int(pos_label[i])\n",
    "        pos_subdata[label, pos_labelindex[label]] = data[i]\n",
    "        pos_labelindex[label] = pos_labelindex[label] + 1\n",
    "\n",
    "    f = h5py.File(data_dir + \"data_for_RSA/ERP/\" + sub + \".h5\", \"w\")\n",
    "    f.create_dataset(\"ori\", data=ori_subdata)\n",
    "    f.create_dataset(\"pos\", data=pos_subdata)\n",
    "    f.close()\n",
    "    print(sub)\n",
    "\n",
    "nsubs = len(subs)\n",
    "data_ori_ERP = np.zeros([16, nsubs, 40, 27, 500], dtype=np.float)\n",
    "data_pos_ERP = np.zeros([16, nsubs, 40, 27, 500], dtype=np.float)\n",
    "subindex = 0\n",
    "for sub in subs:\n",
    "    print('Loading data of sub'+sub)\n",
    "    f = h5py.File(data_dir+'data_for_RSA/ERP/'+sub+'.h5', 'r')\n",
    "    ori_subdata = np.array(f['ori'])\n",
    "    pos_subdata = np.array(f['pos'])\n",
    "    f.close()\n",
    "    data_ori_ERP[:, subindex] = ori_subdata\n",
    "    data_pos_ERP[:, subindex] = pos_subdata\n",
    "    subindex = subindex + 1\n",
    "\n",
    "# calculate the RDMs\n",
    "\n",
    "print(\"\\nCalculate the Orientation RDMs!\")\n",
    "RDM_ori_ERP = eegRDM(data_ori_ERP, sub_opt=1, chl_opt=0, time_opt=1, time_win=5, time_step=5)\n",
    "print(\"\\nCalculate the Position RDMs!\")\n",
    "RDM_pos_ERP = eegRDM(data_pos_ERP, sub_opt=1, chl_opt=0, time_opt=1, time_win=5, time_step=5)\n",
    "# shape of RDMs: [5, 100, 16, 16]\n",
    "\n",
    "# establish a Coding RDM\n",
    "model_RDM = np.zeros([16, 16], dtype=np.float)\n",
    "for i in range(16):\n",
    "    for j in range(16):\n",
    "        diff = np.abs(i - j)\n",
    "        if diff <= 8:\n",
    "            model_RDM[i, j] = diff / 8\n",
    "        else:\n",
    "            model_RDM[i, j] = (16 - diff) / 8\n",
    "\n",
    "conditions = [\"0°\", \"22.5°\", \"45°\", \"67.5°\", \"90°\", \"112.5°\", \"135°\", \"157.5°\", \"180°\",\n",
    "              \"202.5°\", \"225°\", \"247.5°\", \"270°\", \"292.5°\", \"315°\", \"337.5°\"]\n",
    "\n",
    "# plot the Coding RDM\n",
    "print(\"Coding RDM!\")\n",
    "plot_rdm(model_RDM, percentile=True, conditions=conditions)\n",
    "\n",
    "# calculate the CTSimilarities between CTRDMs and Coding RDM\n",
    "print(\"\\nCalculate the Similarities of Orientation!\")\n",
    "Sim_ori_ERP = rdms_corr(model_RDM, RDM_ori_ERP)\n",
    "print(\"\\nCalculate the Similarities of Position!\")\n",
    "Sim_pos_ERP = rdms_corr(model_RDM, RDM_pos_ERP)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 5: Plot the RSA-based decoding results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot orientation decoding results\n",
    "print(\"Orientation RSA-based Decoding Results!\")\n",
    "plot_tbytsim_withstats(Sim_ori_ERP, start_time=-0.5, end_time=1.5, color='orange', lim=[-0.1, 0.5])\n",
    "\n",
    "# plot position decoding results\n",
    "print(\"Position RSA-based Decoding Results!\")\n",
    "plot_tbytsim_withstats(Sim_pos_ERP, start_time=-0.5, end_time=1.5, color='orange', lim=[-0.1, 0.5])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
